{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5dcbf95-9a30-416d-afed-d5b2bf0e8651",
   "metadata": {},
   "source": [
    "# GraphRAG with MongoDB and LangChain\n",
    "\n",
    "This notebook is a companion to the **Graph Retrieval-Augmented Generation (GraphRAG)** page. Refer to the page for set-up instructions and detailed explanations.\n",
    "\n",
    "This notebook walks you through a **GraphRAG implementation using MongoDB Atlas**, leveraging **Atlas Search** and **LangChain's MongoDBGraphStore**. Unlike traditional vector-based RAG, GraphRAG enhances retrieval by structuring knowledge as a graph, allowing for **relationship-aware retrieval and multi-hop reasoning**.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- **Automatically construct a knowledge graph** from documents using an LLM.\n",
    "- **Store and query entity relationships** within MongoDB.\n",
    "- **Retrieve context-aware responses** by combining knowledge graph traversal with LLM-generated answers.\n",
    "\n",
    "By the end of this notebook, you will have a working **GraphRAG implementation** that improves accuracy and explainability in retrieval-augmented generation systems.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mongodb/docs-notebooks/blob/main/use-cases/graphrag.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f70093-83ea-4ecc-87db-2f2f89e546d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/thibaut.gourdel/Documents/jupyterlab/myenv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --quiet --upgrade pymongo langchain_community wikipedia langchain_openai langchain_mongodb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96955f9-a370-4f45-970d-ef187ee6195c",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before you begin, make sure you have the following set up:\n",
    "\n",
    "- An Atlas cluster up and running (you'll need the [connection string](https://www.mongodb.com/docs/guides/atlas/connection-string/))\n",
    "- An OpenAI API key to use GPT-4o as the LLM  *(You can switch the chat model using [LangChain integrations](https://python.langchain.com/docs/integrations/chat/))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0119b58d-f14e-4f36-a284-345d94478537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ATLAS_CONNECTION_STRING = (\"<connection-string>\")\n",
    "ATLAS_DB_NAME = \"documents\"\n",
    "ATLAS_COLLECTION = \"wikipedia\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<openai-api-key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf858b1-dcc2-4bca-bac9-24d62fa6e54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to your local Atlas deployment or Atlas Cluster\n",
    "client = MongoClient(ATLAS_CONNECTION_STRING)\n",
    "\n",
    "# Select the sample_airbnb.listingsAndReviews collection\n",
    "collection = client[ATLAS_DB_NAME][ATLAS_COLLECTION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4e8db2f-d918-41aa-92f8-41f80a6d747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Set up LLM\n",
    "# We strongly recommend using the best models such as gpt-40, claude sonnet 3.5+, etc for best results\n",
    "chatModel = init_chat_model(\"gpt-4o\", model_provider=\"openai\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a312a62-0ce1-48f1-a26b-50ba919151b3",
   "metadata": {},
   "source": [
    "## Load Data from Wikipedia\n",
    "\n",
    "Wikipedia is a rich source of unstructured information. Using the LangChain Wikipedia loader, you can fetch multiple pages for a given query. \n",
    "\n",
    "Unlike traditional vector-based RAG, which struggles to capture relationships across scattered content, GraphRAG links entities and concepts across pages—making Wikipedia an ideal use case for demonstrating how GraphRAG connects the dots for deeper insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72cd5c08-e17b-4f47-bca7-ded0fb25fb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "# Load Wikipedia pages corresponding to the query \"Large Language Models\"\n",
    "wikipedia_pages = WikipediaLoader(query=\"Sherlock Holmes\", load_max_docs=3).load()\n",
    "len(wikipedia_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "436876a3-419f-44af-87b7-d74bade6cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into chunks for efficient downstream processing (graph creation)\n",
    "text_splitter = TokenTextSplitter(chunk_size=1024, chunk_overlap=0)\n",
    "wikipedia_docs = text_splitter.split_documents(wikipedia_pages)\n",
    "\n",
    "# Print the first document\n",
    "# wikipedia_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71f37438-d3e4-485f-baf1-125b69a38269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc164ff6-b357-45c3-8850-26dceb0a1f59",
   "metadata": {},
   "source": [
    "## Create and load the knowledge graph in MongoDB\n",
    "\n",
    "MongoDB stores graph-like structures by using **document references** within collections. Each document acts as a **node (entity)**, and relationships are represented by fields that reference **other documents**, forming **edges** in the graph.\n",
    "\n",
    "With MongoDB’s `$graphLookup` aggregation stage used behind the scene by the MongoDBGraphStore class, you can perform **recursive traversals** to query related entities, enabling efficient **graph-style queries** directly within the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2dc8f05b-0f9a-4293-b9ea-761030c98dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BulkWriteResult({'writeErrors': [], 'writeConcernErrors': [], 'nInserted': 0, 'nUpserted': 7, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': [{'index': 0, '_id': 'Sherlock Holmes'}, {'index': 1, '_id': 'Arthur Conan Doyle'}, {'index': 2, '_id': 'Dr. John H. Watson'}, {'index': 3, '_id': 'Joseph Bell'}, {'index': 4, '_id': 'Sir Henry Littlejohn'}, {'index': 5, '_id': 'C. Auguste Dupin'}, {'index': 6, '_id': 'Monsieur Lecoq'}]}, acknowledged=True)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mongodb.graphrag.graph import MongoDBGraphStore\n",
    "\n",
    "# Set up a MongoDBGraphStore to point to the collection storing the graph-like structure\n",
    "# Also provide the LLM model used for entity extraction for both knowledge graph creation and query entity extraction\n",
    "store = MongoDBGraphStore(connection_string=ATLAS_CONNECTION_STRING, database_name=ATLAS_DB_NAME, collection_name=ATLAS_COLLECTION, entity_extraction_model=chatModel )\n",
    "\n",
    "# Extract entity and create Knowledge graph and load into MongoDB\n",
    "store.add_documents(wikipedia_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b167c2eb-b2c5-45ef-bdc9-8230f7da4c52",
   "metadata": {},
   "source": [
    "## Visualize the knowledge graph\n",
    "\n",
    "To **visualize the knowledge graph**, you can export the structured data to visualization libraries like pyvis.\n",
    "\n",
    "This makes it easy to explore and understand the relationships and hierarchies within your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b515723-a8a4-435b-b386-5cb3244c2745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"550px\"\n",
       "            src=\"graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x119a16880>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(ATLAS_CONNECTION_STRING)\n",
    "collection = client[ATLAS_DB_NAME][ATLAS_COLLECTION]\n",
    "\n",
    "docs = list(collection.find())\n",
    "\n",
    "# Function to convert attributes dictionary to a display string\n",
    "def format_attributes(attributes):\n",
    "    if not attributes:\n",
    "        return \"\"\n",
    "    parts = []\n",
    "    for key, values in attributes.items():\n",
    "        parts.append(f\"{key}: {', '.join(values)}\")\n",
    "    return \"<br>\".join(parts)\n",
    "\n",
    "# Create a NetworkX graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes with their attributes\n",
    "for doc in docs:\n",
    "    node_id = doc[\"_id\"]\n",
    "    # Combine document type and its attributes (if any) for the hover tooltip\n",
    "    node_info = f\"Type: {doc.get('type', '')}\"\n",
    "    if \"attributes\" in doc:\n",
    "        attr_str = format_attributes(doc[\"attributes\"])\n",
    "        if attr_str:\n",
    "            node_info += \"<br>\" + attr_str\n",
    "    G.add_node(node_id, title=node_info, label=node_id)\n",
    "\n",
    "# Add edges based on relationships\n",
    "for doc in docs:\n",
    "    source = doc[\"_id\"]\n",
    "    rels = doc.get(\"relationships\", {})\n",
    "    target_ids = rels.get(\"target_ids\", [])\n",
    "    rel_types = rels.get(\"types\", [])\n",
    "    rel_attrs = rels.get(\"attributes\", [])\n",
    "    \n",
    "    # Ensure all three lists have the same length\n",
    "    for i in range(len(target_ids)):\n",
    "        target = target_ids[i]\n",
    "        edge_type = rel_types[i] if i < len(rel_types) else \"\"\n",
    "        # Get edge attributes info if available\n",
    "        extra_attr = {}\n",
    "        if i < len(rel_attrs) and rel_attrs[i]:\n",
    "            extra_attr = rel_attrs[i]\n",
    "        edge_info = f\"Relationship: {edge_type}\"\n",
    "        if extra_attr:\n",
    "            edge_info += \"<br>\" + format_attributes(extra_attr)\n",
    "        # Add the edge with title attribute for hover\n",
    "        G.add_edge(source, target, title=edge_info, label=edge_type)\n",
    "\n",
    "# Create and show the network using pyvis\n",
    "net = Network(height=\"550px\", width=\"100%\", notebook=True, directed=True)\n",
    "net.from_nx(G)\n",
    "net.show(\"graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea568d-c656-4271-9e40-6ee01292255e",
   "metadata": {},
   "source": [
    "## LLM-based Question Answering with Graph Retrieval (GraphRAG)\n",
    "\n",
    "The `MongoDBGraphStore` class offers a convenient `chat_response` method that enables LLM-based question answering grounded in graph data. This method retrieves relevant entities and relationships from the graph based on the user query to generate accurate and context-aware responses.\n",
    "\n",
    "Use this for building intelligent assistants that leverage structured knowledge graphs for enhanced understanding and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "506c7366-972c-4e50-88c4-3d5b0151e363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sherlock Holmes was inspired by Dr. Joseph Bell, a lecturer at the University of Edinburgh, known for his keen observational skills and logical reasoning, which greatly influenced Arthur Conan Doyle, the creator of Sherlock Holmes.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who inspired Sherlock Holmes?\"\n",
    "\n",
    "answer = store.chat_response(query)\n",
    "answer.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
